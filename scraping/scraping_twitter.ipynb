{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6893be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a3ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "\n",
    "web = \"https://twitter.com/i/flow/login\"\n",
    "driver.get(web)\n",
    "\n",
    "# wait of 6 seconds to let the page load the content\n",
    "time.sleep(6)  # this time might vary depending the network\n",
    "\n",
    "twitter_email = ''\n",
    "twitter_username = ''\n",
    "twitter_password = ''\n",
    "\n",
    "username = driver.find_element(By.XPATH,'//input[@autocomplete =\"username\"]')\n",
    "username.send_keys(twitter_email)\n",
    "\n",
    "\n",
    "\n",
    "# Clicking on \"Next\" button\n",
    "next_button = driver.find_element(By.XPATH,'//div[@role=\"button\"]//span[text()=\"Next\"]')\n",
    "next_button.click()\n",
    "time.sleep(5)\n",
    "\n",
    "# anti_check = driver.find_element(By.XPATH,'//input[@autocapitalize=\"none\"]')\n",
    "# anti_check.send_keys(twitter_username)\n",
    "\n",
    "# # Clicking on \"Next\" button\n",
    "# next_button = driver.find_element(By.XPATH,'//div[@role=\"button\"]//span[text()=\"Next\"]')\n",
    "# next_button.click()\n",
    "# time.sleep(5)\n",
    "\n",
    "\n",
    "# locate password textbox\n",
    "password = driver.find_element(By.XPATH,'//input[@autocomplete =\"current-password\"]')\n",
    "password.send_keys(twitter_password) \n",
    "\n",
    "\n",
    "# locating login button and then clicking on it\n",
    "login_button = driver.find_element(By.XPATH, '//div[@role=\"button\"]//span[text()=\"Log in\"]')\n",
    "login_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d85291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'Python'\n",
    "search_button = driver.find_element(By.XPATH,'//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div[2]/div/div[2]/div/div/div/div[1]/div/div/div/form/div[1]/div/div/div/label/div[2]/div/input')\n",
    "search_button.send_keys(topic)\n",
    "search_button.send_keys(Keys.ENTER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b3cce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "12\n",
      "12\n",
      "5\n",
      "10\n",
      "9\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "3\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "13\n",
      "13\n",
      "13\n",
      "6\n",
      "length reached\n",
      "False\n",
      "                user                                               text\n",
      "0    @SwissCognitive  Required #DataScience skills By: coders learni...\n",
      "1      @Jensen_Hacks  Useful roadmap for #Python #MachineLearning #D...\n",
      "2            @tut_ml  Learn Data Science with these FREE Online Cour...\n",
      "3     @ezekiel_aleke  Python SQL PowerBI Excel Statistics Tableau and I\n",
      "4     @python_spaces  If you want to get started with Python, check ...\n",
      "..               ...                                                ...\n",
      "99      @gmrpetricca  2023-03-08 M5.8 #Kuril Islands #earthquake rec...\n",
      "100  @Mountaingoat55  I find it hard to understand how 2 anti extabl...\n",
      "101     @Newcoupon01  Udemy Free Discount - Write PHP Like a Pro: Bu...\n",
      "102       @OpShinDev  Introducing: hebi Part of the op-shin (#eopsin...\n",
      "103      @driscollis  What is your favorite science-related #Python ...\n",
      "\n",
      "[104 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(driver.page_source)\n",
    "# soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "# postings = soup.find_all('div', class_=\"css-901oao r-18jsvk2 r-37j5jr r-a023e6 r-16dba41 r-rjixqe r-bcqeeo r-bnwqim r-qvutc0\")\n",
    "# tweets = []\n",
    "\n",
    "# while True:\n",
    "#     for post in postings:\n",
    "#         tweets.append(post.text)\n",
    "#     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#     time.sleep(3)\n",
    "#     soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "#     postings = soup.find_all('div', class_=\"css-901oao r-18jsvk2 r-37j5jr r-a023e6 r-16dba41 r-rjixqe r-bcqeeo r-bnwqim r-qvutc0\")\n",
    "#     tweets2 = list(set(tweets))\n",
    "#     if len(tweets2) > 200:\n",
    "#         break\n",
    "\n",
    "def get_tweet(element):\n",
    "    \"\"\"This function scrapes data of tweets. It returns a list with 2 elements; username and text\"\"\"\n",
    "    try:\n",
    "        user = element.find_element(By.XPATH, \".//span[contains(text(), '@')]\").text\n",
    "        text = element.find_element(By.XPATH, \".//div[@lang]\").text\n",
    "        tweets_data = [user, text]\n",
    "    except:\n",
    "        tweets_data = ['user', 'text']\n",
    "    return tweets_data\n",
    "\n",
    "user_data = []\n",
    "text_data = []\n",
    "tweet_ids = set()\n",
    "scrolling = True\n",
    "while scrolling:\n",
    "    tweets = WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, \"//article[@role='article']\")))\n",
    "    print(len(tweets))\n",
    "    # you can change this number with the number of tweets in a website || \n",
    "    # NOTE: ONLY THOSE LOADED IN THE last page will be considered while those from previous page will be forgotten (example: scroll all the way down and then try to find an @username that it's on top --> it won't find it)\n",
    "    for tweet in tweets[-15:]: \n",
    "        tweet_list = get_tweet(tweet)\n",
    "        tweet_id = ''.join(tweet_list)\n",
    "        if tweet_id not in tweet_ids:\n",
    "            tweet_ids.add(tweet_id)\n",
    "            user_data.append(tweet_list[0])\n",
    "            text_data.append(\" \".join(tweet_list[1].split()))\n",
    "\n",
    "    # Get the initial scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        # Wait to load page\n",
    "        time.sleep(3)\n",
    "        # Calculate new scroll height and compare it with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        # break according to the height is not work now \n",
    "#         if new_height == last_height:  # if the new and last height are equal, it means that there isn't any new page to load, so we stop scrolling\n",
    "#             print('height reached')\n",
    "#             scrolling = False\n",
    "#             break\n",
    "#       break condition based on the number of rows we get works.\n",
    "        if len(user_data) > 100: #get 100 data\n",
    "            print('length reached')\n",
    "            scrolling = False\n",
    "            break\n",
    "        else:\n",
    "            last_height = new_height\n",
    "            break\n",
    "\n",
    "\n",
    "# driver.quit()\n",
    "print(scrolling)\n",
    "df_tweets = pd.DataFrame({'user': user_data, 'text': text_data})\n",
    "df_tweets.to_csv('tweets.csv', index=False)\n",
    "print(df_tweets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2809511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               user                                               text\n",
      "0          @greggyb  Built a command line chatbot in Python with th...\n",
      "1  @Fabriziobustama  Mixed reality play space blending physical & v...\n",
      "2        @buildkite  Deploy at scale with our free Developer Plan. ...\n",
      "3    @SecurityTrybe  Cybersecurity Roadmap 2023 #CyberSecurityAware...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# web = \"https://twitter.com/search?q=python&src=typed_query\"\n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "# driver.get(web)\n",
    "# driver.maximize_window()\n",
    "\n",
    "# user_data = []\n",
    "# text_data = []\n",
    "\n",
    "# def get_tweet(element):\n",
    "#     \"\"\"This function scrapes data of tweets. It returns a list with 2 elements; username and text\"\"\"\n",
    "#     try:\n",
    "#         user = element.find_element(By.XPATH, \".//span[contains(text(), '@')]\").text\n",
    "#         text = element.find_element(By.XPATH, \".//div[@lang]\").text\n",
    "#         tweets_data = [user, text]\n",
    "#     except:\n",
    "#         tweets_data = ['user', 'text']\n",
    "#     return tweets_data\n",
    "\n",
    "\n",
    "# # Getting all the tweet cards/boxes listed in a single page\n",
    "# tweets = WebDriverWait(driver, 5).until(EC.presence_of_all_elements_located((By.XPATH, \"//article[@role='article']\")))\n",
    "\n",
    "\n",
    "# for tweet in tweets:\n",
    "#     tweet_list = get_tweet(tweet)  # calling the function get_tweet to scrape data of the tweets list\n",
    "#     user_data.append(tweet_list[0])  # appending the first element of tweet_list (user)\n",
    "#     text_data.append(\" \".join(tweet_list[1].split()))  # appending the second element of tweet_list (text)\n",
    "    \n",
    "    \n",
    "\n",
    "# df_tweets = pd.DataFrame({'user': user_data, 'text': text_data})\n",
    "# df_tweets.to_csv('tweets.csv', index=False)\n",
    "# print(df_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da410df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# web='https://twitter.com/CommunityNotes/status/1628158167006994436?cxt=HHwWiIDT6b_OsJgtAAAA'\n",
    "\n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "# driver.get(web)\n",
    "# driver.maximize_window()\n",
    "\n",
    "# last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "# while True:\n",
    "#     # Scroll down to bottom\n",
    "#     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#     # Wait to load page\n",
    "#     time.sleep(5)\n",
    "#     # Calculate new scroll height and compare it with last scroll height\n",
    "#     new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#     if new_height == last_height:  # if the new and last height are equal, it means that there isn't any new page to load, so we stop scrolling\n",
    "#         break\n",
    "#     else:\n",
    "#         last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c35f2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# web='https://twitter.com/CommunityNotes/status/1628158167006994436?cxt=HHwWiIDT6b_OsJgtAAAA'\n",
    "\n",
    "# driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "# driver.get(web)\n",
    "# driver.maximize_window()\n",
    "\n",
    "# last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "# scroll_count = 0\n",
    "# while scroll_count < 10:\n",
    "#     driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#     time.sleep(5)\n",
    "#     new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#     if new_height == last_height:\n",
    "#         break\n",
    "#     last_height = new_height\n",
    "#     scroll_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2738009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
